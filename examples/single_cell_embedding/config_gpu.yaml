general:
  project_name: scembed_test_3
  mamba_env: scembed
  entity: spatial_vi
  modules: stack eth_proxy
  count: 1 # single run per job, good for longer running jobs to avoid time outs.

slurm:
  time: "01:00:00"
  mem_per_cpu: "16G"
  job_name: scembed_gpu
  output: slurm_logs/gpu_%A_%a.out
  array: "0-15"
  gpus: rtx_4090:1

wandb:
  program: train.py
  method: grid
  name: gpu_methods
  metric:
    goal: maximize
    name: scib_total_score
  parameters:
    config:
      values: [
        # Harmony
        {"method": "harmony", "theta": 1.0},
        {"method": "harmony", "theta": 2.0},
        {"method": "harmony", "theta": 5.0},

        # scVI
        {"method": "scvi"} # default
        {"method": "scvi", "n_latent": 10, "n_layers": 1},
        {"method": "scvi", "n_latent": 10, "n_layers": 2},
        {"method": "scvi", "n_latent": 30, "n_layers": 1},
        {"method": "scvi", "n_latent": 30, "n_layers": 2},
        {"method": "scvi", "n_latent": 50, "n_layers": 1},
        {"method": "scvi", "n_latent": 50, "n_layers": 2},

        # scANVI
        {"method": "scanvi"}, # default
        {"method": "scanvi", "scvi_params": {"n_latent": 10, "n_layers": 2, "max_epochs": 50, "early_stopping": true}},
        {
                    # scANVI tutorial + larger hidden size
                    method: scanvi,
                    n_samples_per_label: 100,
                    max_epochs: 20,
                    early_stopping: true,
                    scvi_params:
                        {
                            n_latent: 30,
                            n_layers: 2,
                            gene_likelihood: "nb",
                            n_hidden: 256,
                        },
                }

        # scPoli
        {"method": "scpoli"}, # default
        {"method": "scpoli", "embedding_dims": 5, "n_epochs": 50, "pretraining_epochs": 40},
        {"method": "scpoli", "embedding_dims": 10, "n_epochs": 50, "pretraining_epochs": 40}
      ]
