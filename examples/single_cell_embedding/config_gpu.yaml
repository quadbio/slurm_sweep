general:
  project_name: scembed_gpu_comparison
  mamba_env: scembed
  entity: spatial_vi
  modules: stack eth_proxy

slurm:
  time: "01:00:00"
  mem_per_cpu: "16G"
  job_name: scembed_gpu
  output: slurm_logs/gpu_%A_%a.out
  array: "0-15"
  gpus: rtx_4090:1

wandb:
  program: train.py
  method: grid
  name: gpu_methods
  metric:
    goal: maximize
    name: scib_total_score
  parameters:
    config:
      values: [
        # Harmony - theta parameter values
        {"method": "harmony", "theta": 1.0},
        {"method": "harmony", "theta": 2.0},
        {"method": "harmony", "theta": 5.0},

        # scVI - all combinations of n_latent and n_layers
        {"method": "scvi", "n_latent": 10, "n_layers": 1},
        {"method": "scvi", "n_latent": 10, "n_layers": 2},
        {"method": "scvi", "n_latent": 30, "n_layers": 1},
        {"method": "scvi", "n_latent": 30, "n_layers": 2},
        {"method": "scvi", "n_latent": 50, "n_layers": 1},
        {"method": "scvi", "n_latent": 50, "n_layers": 2},

        # scANVI - all combinations of n_latent and max_epochs_scanvi (n_layers fixed at 2)
        {"method": "scanvi", "n_latent": 10, "n_layers": 2, "max_epochs_scanvi": 20},
        {"method": "scanvi", "n_latent": 10, "n_layers": 2, "max_epochs_scanvi": 50},
        {"method": "scanvi", "n_latent": 30, "n_layers": 2, "max_epochs_scanvi": 20},
        {"method": "scanvi", "n_latent": 30, "n_layers": 2, "max_epochs_scanvi": 50},

        # scPoli - all combinations of embedding_dims (n_epochs and pretraining_epochs fixed)
        {"method": "scpoli", "embedding_dims": 5, "n_epochs": 50, "pretraining_epochs": 40},
        {"method": "scpoli", "embedding_dims": 10, "n_epochs": 50, "pretraining_epochs": 40}
      ]
